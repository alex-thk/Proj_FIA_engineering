import numpy as npimport pandas as pdfrom collections import Counterfrom sklearn.metrics import silhouette_samplesfrom hyperparameter_tuner import HyperparameterTunerfrom sklearn.datasets import make_blobsfrom data_standardization import FeatureScalerclass ClusteringResultAnalyzer:    def __init__(self, labels, data, centroids=None, y_true=None):        """        Inizializza l'analizzatore di clustering.        :param labels: Etichette dei cluster assegnati dal modello (obbligatorio)        :param data: Dataset originale (obbligatorio)        :param centroids: Centroidi dei cluster (opzionale, solo se il modello li fornisce)        :param y_true: Etichette di classe reali per calcolare la purità (opzionale)        """        self.labels = labels        self.centroids = centroids        self.data = data        self.y_true = y_true  # Etichette vere, opzionale    def cluster_summary(self):        """        Crea una tabella riassuntiva che mostra la numerosità, la purità e la silhouette media per cluster.        """        unique_labels, counts = np.unique(self.labels, return_counts=True)        # Tabella base con numerosità per cluster        summary_table = pd.DataFrame({            'Cluster': unique_labels,            'Numerosity': counts        })        # Calcolo delle silhouette per ogni campione        silhouette_vals = silhouette_samples(self.data, self.labels)        # Liste per silhouette media e purità        silhouette_avg_per_cluster = []        purity_list = []        # Ciclo su ciascun cluster per calcolare sia silhouette media che purità (se y_true è disponibile)        for label in unique_labels:            # Prendi le silhouette dei campioni appartenenti al cluster corrente            silhouette_vals_for_cluster = silhouette_vals[self.labels == label]            # Calcola la media delle silhouette per il cluster            silhouette_avg = np.mean(silhouette_vals_for_cluster)            silhouette_avg_per_cluster.append(silhouette_avg)            true_labels_in_cluster = self.y_true[self.labels == label].flatten()            most_common_class_count = Counter(true_labels_in_cluster).most_common(1)[0][1]            purity = most_common_class_count / len(true_labels_in_cluster)            purity_list.append(purity)        # Aggiungi la silhouette media alla tabella        summary_table['Avg Silhouette '] = silhouette_avg_per_cluster        # Aggiungi la purità alla tabella, se disponibile        summary_table['Purity'] = purity_list        return summary_table    def display_summary(self):        """        Mostra la tabella riassuntiva dei cluster.        """        summary_table = self.cluster_summary()        # Usa Pandas per visualizzare la tabella        print(summary_table)    def analyze_centroids(self):        """        Analizza i centroidi, mostrando la loro struttura (se presenti).        """        if self.centroids is not None:            print("Centroidi dei cluster:")            pd.set_option('display.max_rows', None)            pd.set_option('display.max_columns', None)            print(pd.DataFrame(self.centroids))        else:            print("Questo algoritmo non fornisce centroidi.")# Test del tuner protetto da __name__if __name__ == "__main__":    # Generiamo un dataset artificiale    data, labels = make_blobs(n_samples=200, centers=4, n_features=2, random_state=42)    data_df = pd.DataFrame(data, columns=['feature1', 'feature2'])    scaler = FeatureScaler()    data_df, stats, list_of_cols = scaler.standardize(data_df, ['feature1'])    # Definizione della griglia di iperparametri per il tuning    param_grid = {        'n_clusters': [2, 3, 4, 5],  # numero di cluster che vogliamo testare    }    data_df = scaler.standardize_(data_df, ['feature2'])    # Istanzia il tuner per KMeans    tuner = HyperparameterTuner(algorithm='kmeans', param_grid=param_grid, data=data_df, labels=labels)    # Eseguiamo il Grid Search per trovare la combinazione migliore di iperparametri    results = tuner.perform_grid_search()    # Ora estrai i singoli valori dal dizionario `results`    best_params = results['best_params']    best_score = results['best_score']    best_labels = results['best_labels']    best_centroids = results['best_centroids']    best_centroids_us = scaler.inverse_standardize_centroids(best_centroids, stats, list_of_cols)    # Stampa i valori corretti per verificare    print(f" i centroidi che passo a ClusteringResultAnalyzer sono: {best_centroids_us}")    print(f" i labels che passo a ClusteringResultAnalyzer sono: {best_labels}")    print(f" il miglior score che passo a ClusteringResultAnalyzer è: {best_score}")    print(f" i migliori param che passo a ClusteringResultAnalyzer sono: {best_params}")    # Passiamo i parametri separati a ClusteringResultAnalyzer    analyzer = ClusteringResultAnalyzer(        labels=best_labels,  # Passiamo le migliori etichette        data=data_df,  # Dati originali        centroids=best_centroids_us,  # Passiamo i migliori centroidi        y_true=labels  # Etichette vere per il calcolo della purezza    )    # Ora puoi chiamare i metodi dell'analyzer    analyzer.display_summary()    analyzer.analyze_centroids()